{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt\">MIPT, Advanced ML, Autumn 2017</span>\n",
    "\n",
    "<span style=\"font-size: 16pt\"> HW #9: Recommendation System\n",
    "\n",
    "<span style=\"color:blue; font-size: 12pt\">Andrey Saitgalin </span>\n",
    "<span style=\"color:blue; font-size: 12pt; font-family: 'Verdana'\">andrey.saitgalin@gmail.com</span>, \n",
    "\n",
    "<span style=\"color:blue; font-size: 12pt\">Alexey Dral </span>,\n",
    "<span style=\"color:blue; font-size: 12pt; font-family: 'Verdana'\">aadral@gmail.com</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Organization Info</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Дополнительный материал для выполнения дз**:\n",
    "<a href= \"https://github.com/ml-mipt/ml-mipt-part2/tree/master/2017/lectures\">Лекции по курсу</a>\n",
    "\n",
    "**Оформление дз**: \n",
    "- Присылайте выполненное задание на почту ``ml.course.mipt@gmail.com``\n",
    "- Укажите тему письма в следующем формате ``ML2017_Aut_fall <номер_группы> <фамилия>``, к примеру -- ``ML2017_Aut_fall 401 ivanov``\n",
    "- Выполненное дз сохраните в файл ``<фамилия>_<группа>_task<номер>.ipnb``, к примеру -- ``ivanov_491_task9.ipnb``\n",
    "\n",
    "**Вопросы**:\n",
    "- Присылайте вопросы на почту ``ml.course.mipt@gmail.com``\n",
    "- Укажите тему письма в следующем формате ``ML2017_Aut_fall Question <Содержание вопроса>``\n",
    "\n",
    "** Дедлайн**:\n",
    "<span style=\"color:red; font-size: 12pt\">16.12.2017 23:59 </span>\n",
    "\n",
    "--------\n",
    "- **PS1**: Мы используем автоматические фильтры, и просто не найдем ваше дз, если вы не аккуратно его подпишите.\n",
    "- **PS2**: Напоминаем, что дедлайны жесткие, письма пришедшие после автоматически удаляются =( чтобы соблазна не было."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Check Questions (0%)</h1> \n",
    "Вопросы отсутствуют - cool!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Practical tasks (100%)</h1>\n",
    "\n",
    "\n",
    "# Построение content-based рекомендательной системы\n",
    "## Part 1\n",
    "Для каждого фильма получите описание в текстовом виде с IMDB или (и) The movie database (у них есть открытое API). https://www.themoviedb.org/?language=ru. Вывести описание фильма под id 778. Также можно использовать рецензии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tmdbsimple as tmdb\n",
    "from scipy.spatial.distance import cosine\n",
    "from tqdm import tqdm\n",
    "import pickle \n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"keys.cfg\",\"r\") as f:\n",
    "    tmdb.API_KEY = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monsieur  Hulot's Holiday\n",
      "Monsieur Hulot, Jacques Tati’s endearing clown, takes a holiday at a seaside resort, where his presence provokes one catastrophe after another. Tati’s masterpiece of gentle slapstick is a series of effortlessly well-choreographed sight gags involving dogs, boats, and firecrackers; it was the first entry in the Hulot series and the film that launched its maker to international stardom.\n"
     ]
    }
   ],
   "source": [
    "movie = tmdb.Movies(778)\n",
    "overview = movie.info()['overview']\n",
    "title = movie.title\n",
    "print(title)\n",
    "print(overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def read_films(ids, sleep_time=0.00001):\n",
    "    film_ids, titles, overviews = [],[],[]\n",
    "    for i in ids:\n",
    "        time.sleep(sleep_time)\n",
    "        try:\n",
    "            movie = tmdb.Movies(i)\n",
    "            info = movie.info()\n",
    "            title = info['title']\n",
    "            overview = info['overview']\n",
    "        except:\n",
    "            continue\n",
    "        titles.append(title)\n",
    "        overviews.append(overview)\n",
    "        film_ids.append(i)\n",
    "    dict_to_save = {'film_ids':film_ids, 'titles':titles, 'overviews':overviews}\n",
    "    np.save('uploaded_films_{}_{}.npy'.format(ids[0],ids[-1]) , dict_to_save)\n",
    "    return film_ids, titles, overviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read_films(range(20000,35000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untitled.ipynb                 uploaded_films_1000_4999.npy\r\n",
      "keys.cfg                       uploaded_films_200_209.npy\r\n",
      "\u001b[34mml-20m\u001b[m\u001b[m                         uploaded_films_210_999.npy\r\n",
      "movie_data.npy                 uploaded_films_5000_9999.npy\r\n",
      "pickle_movies.pkl              zotov_497_task9.ipynb\r\n",
      "uploaded_films_10000_19999.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LOAD FILES\n",
    "FNAMES = [\n",
    "    'uploaded_films_10000_19999.npy', \n",
    "    'uploaded_films_5000_9999.npy',\n",
    "    'uploaded_films_1000_4999.npy',\n",
    "    'uploaded_films_210_999.npy',\n",
    "    'uploaded_films_200_209.npy',\n",
    "]\n",
    "def read_files_1():\n",
    "    ids = []\n",
    "    descriptions = []\n",
    "    titles = []\n",
    "    for f in FNAMES:\n",
    "        d = np.load(f).item()\n",
    "        ids += d['film_ids']\n",
    "        descriptions += d['overviews']\n",
    "        titles += d['titles']\n",
    "    return ids, descriptions, titles\n",
    "\n",
    "def read_files_2():\n",
    "    d = np.load('pickle_movies.pkl')\n",
    "    keys = list(d.keys())\n",
    "    descriptions = [d[k]['overview'] for k in keys]\n",
    "    titles = [d[k]['title'] for k in keys]\n",
    "    return keys, descriptions, titles\n",
    "    \n",
    "def build_mapping(ids):\n",
    "    val_to_i, i_to_val = {},{}\n",
    "    for index, value in enumerate(ids):\n",
    "        i_to_val[index] = value\n",
    "        val_to_i[value] = index\n",
    "    return val_to_i, i_to_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180283"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids, descriptions, titles = read_files_2()\n",
    "val_to_i, i_to_val = build_mapping(ids)\n",
    "# print(len(val_to_i) , len(i_to_val))\n",
    "assert len(val_to_i) == len(i_to_val)\n",
    "assert len(ids) == len(descriptions) and len(ids) == len(titles)\n",
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.txt        genome-tags.csv   movies.csv        tags.csv\r\n",
      "genome-scores.csv links.csv         ratings.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ml-20m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 \n",
    "Извлеките текстовые признаки у фильмов: tf idf, биграммы (может какие-то еще). Биграммы - статистика по биграммам, сколько какая биграмма встречается. Формулы для TF-IDF смотреть тут: https://en.wikipedia.org/wiki/Tf%E2%80%93idf \n",
    "    1. Используйте TF с double 0.5 normalization\n",
    "    2. Используйте стандартный IDF: \n",
    "$$idf(t, D) = \\frac{log N}{(1 + |d in D : t in d|)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put your code here\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "tf_idf = vectorizer.fit_transform(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180283, 182571)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 \n",
    "Выведите подсчитанные признаки из пункта 2 для фильма с id 99114."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Что это за фильм?\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    movie = tmdb.Movies(99114)\n",
    "    movie.info()\n",
    "except Exception:\n",
    "    print('Что это за фильм?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Django Unchained\n",
      "With the help of a German bounty hunter, a freed slave sets out to rescue his wife from a brutal Mississippi plantation owner.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 182551,\n",
       "         0.054226901019748426: 1,\n",
       "         0.060186406982517274: 1,\n",
       "         0.063990905656852295: 1,\n",
       "         0.086584249974183944: 1,\n",
       "         0.090929609699591615: 1,\n",
       "         0.10225842812652504: 1,\n",
       "         0.13509367380798046: 1,\n",
       "         0.17687076361233151: 1,\n",
       "         0.17759828473771597: 1,\n",
       "         0.22104827310527214: 1,\n",
       "         0.23449642910833335: 1,\n",
       "         0.2404058396076586: 1,\n",
       "         0.24563297889689367: 1,\n",
       "         0.25057658941997746: 1,\n",
       "         0.26855732438532576: 1,\n",
       "         0.29408933912724339: 1,\n",
       "         0.31114951364901228: 1,\n",
       "         0.32687019747671314: 1,\n",
       "         0.34166149708111643: 1,\n",
       "         0.34390885849298591: 1})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ВОТ ОН 68718\n",
    "# mid_to_tmd[99114] == 68718\n",
    "row = tf_idf.getrow(val_to_i[68718])# put your code here\n",
    "print(titles[val_to_i[68718]])\n",
    "print(descriptions[val_to_i[68718]])\n",
    "Counter(np.array(row.todense())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4\n",
    "Для каждого пользователя найдите топ жанров, которые нравятся пользователю (можно делать как на семинаре top 5, top 3 и top 2) и порекомендуйте таким пользователя фильмы близкие по текстовому описанию (см. пункт 2). Для оценки результатов пункта 3 используйте метрику HitRate и метрики ранжирования (N)DCG. Формулу для подсчета HitRate можно взять на семинаре,  (N)DCG: https://en.wikipedia.org/wiki/Discounted_cumulative_gain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>tmdbId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>114709</td>\n",
       "      <td>862.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>113497</td>\n",
       "      <td>8844.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  imdbId  tmdbId\n",
       "0        1  114709   862.0\n",
       "1        2  113497  8844.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = pd.read_csv('ml-20m/links.csv')\n",
    "links.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmd_to_mid = dict(zip(links['tmdbId'], links['movieId']))\n",
    "mid_to_tmd = dict(zip(links['movieId'], links['tmdbId']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68718.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mid_to_tmd[99114]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2873</th>\n",
       "      <td>2959</td>\n",
       "      <td>Fight Club (1999)</td>\n",
       "      <td>Action|Crime|Drama|Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      movieId              title                       genres\n",
       "2873     2959  Fight Club (1999)  Action|Crime|Drama|Thriller"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv('ml-20m/movies.csv')\n",
    "# should be FIGHT CLUB\n",
    "movies[movies['movieId'] == tmd_to_mid[550]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ml-20m/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112486027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1        2     3.5  1112486027\n",
       "1       1       29     3.5  1112484676\n",
       "2       1       32     3.5  1112484819\n",
       "3       1       47     3.5  1112484727\n",
       "4       1       50     3.5  1112484580"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genres\n",
    "\n",
    "Будем считать метрику $\\mathbb{GENRE--TF-IDF}$ популярности жанра у пользователя как :\n",
    "\n",
    "$R = \\frac{\\sum_{\\text{film} \\in \\text{genre}} \\text{rating(film)}}{\\log (\\text{number of films with this genre})}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Film-Noir', 'Documentary', 'Adventure', 'Action', 'Crime', 'Fantasy', 'Comedy', 'Horror', 'Mystery', 'Drama', 'Animation', 'Sci-Fi', 'IMAX', 'Children', 'Western', 'Thriller', 'Romance', 'Musical', '(no genres listed)', 'War']\n"
     ]
    }
   ],
   "source": [
    "genres_counter = Counter('|'.join(movies['genres']).split('|'))\n",
    "genres = list(genres_counter.keys())\n",
    "print(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_to_genres = {}\n",
    "for i in range(movies.shape[0]):\n",
    "    row = movies.iloc[i]\n",
    "    movie_to_genres[row['movieId']] = row['genres'].split('|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:00<00:00, 5562.61it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 5585.08it/s]\n",
      "100%|██████████| 187/187 [00:00<00:00, 4456.09it/s]\n",
      "100%|██████████| 38/38 [00:00<00:00, 5221.92it/s]\n",
      "100%|██████████| 28/28 [00:00<00:00, 2491.31it/s]\n",
      "100%|██████████| 68/68 [00:00<00:00, 5282.40it/s]\n"
     ]
    }
   ],
   "source": [
    "interesting_users = [1,2,3,10,20,666]\n",
    "user_genres_rating = {}\n",
    "for user in interesting_users:\n",
    "    df = ratings[ratings['userId'] == user]\n",
    "    for i in tqdm(range(df.shape[0]),position=0):\n",
    "        row = df.iloc[i]\n",
    "        user_id = int(row['userId'])\n",
    "        movie_id = int(row['movieId'])\n",
    "        rating = int(row['rating'])\n",
    "        movie_genres = movie_to_genres[movie_id]\n",
    "        if user_id not in user_genres_rating:\n",
    "            user_genres_rating[user_id] = dict(zip(genres,list(np.zeros(len(genres)))))\n",
    "        for genre in movie_to_genres[movie_id]:\n",
    "            user_genres_rating[user_id][genre] += rating\n",
    "for user in user_genres_rating.keys():\n",
    "    for genre in user_genres_rating[user].keys():\n",
    "        user_genres_rating[user][genre] /= np.log(genres_counter[genre])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(34.331746395029093, 'Fantasy'), (34.050481751173535, 'Adventure'), (28.654641550454755, 'Action'), (20.082647546334464, 'Horror'), (18.4903238872771, 'Sci-Fi')]\n",
      "[(49.843481783094788, 'Sci-Fi'), (30.736389013521983, 'Action'), (27.214589581430364, 'Adventure'), (25.792671637206286, 'Drama'), (25.546956923122973, 'Thriller')]\n",
      "[(13.054250134749305, 'Drama'), (10.959951185649791, 'Comedy'), (8.6415995353357076, 'Adventure'), (8.3269898522689036, 'Action'), (7.4471736868803804, 'Romance')]\n"
     ]
    }
   ],
   "source": [
    "def get_top_genres(user_id ,n=5):\n",
    "    d = user_genres_rating[user_id]\n",
    "    scores = [(d[k],k) for k in d.keys()]\n",
    "    return sorted(scores,reverse=True)[:n]\n",
    "    \n",
    "print(get_top_genres(1))\n",
    "print(get_top_genres(3))\n",
    "print(get_top_genres(666))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекомендации\n",
    "\n",
    "Посчитаем для каждого фильма из списка предложенных к просмотру конкретному пользователю (еще не просмотренные фильмы) метрику $\\textbf{score}(a)$: \n",
    "$$\n",
    "\\textbf{score}(a) = \\frac{1}{N} \\sum_{i,b=\\text{watched}(i)}^{N} [ \\text{tfidf_cosine_score}(a, b) * \\text{rating}(b) ]\n",
    "$$\n",
    "\n",
    "На словах - взвешенный по рейтингу усредненный cosine_similarity_score по всем просмотренным фильмам. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_recommendation_for_user(watched_films_id, rating, suggesting_list_ids):\n",
    "    watched_tf_idf = tf_idf[watched_films_id]\n",
    "    to_suggest_tf_idf = tf_idf[suggesting_list_ids]\n",
    "    suggested_score = np.array([np.mean([tfidf_cosine_similarity(a,b) \n",
    "                                    for a in watched_tf_idf] * rating)\n",
    "                           for b in to_suggest_tf_idf])\n",
    "    sorted_args = np.flip(np.argsort(suggested_score),axis=-1)\n",
    "    return sorted_args, suggested_score[sorted_args]\n",
    "\n",
    "def tfidf_cosine_similarity(a, b):\n",
    "    a = a.todense()\n",
    "    a = np.ravel(a)\n",
    "    b = b.todense()\n",
    "    b = np.ravel(b)\n",
    "    try:\n",
    "        return -(cosine(a, b) - 1)\n",
    "    except:\n",
    "        pass\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построим рекомендации для нескольких пользователей и посчиатем NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_recommendations(user_id = 1):\n",
    "    user_ratings = ratings[ratings['userId'] == user_id]\n",
    "    train, test = train_test_split(user_ratings,test_size=0.5)\n",
    "\n",
    "    result_id = [],[]\n",
    "    result_ratings = [],[]\n",
    "\n",
    "    indices_list = [train['movieId'], test['movieId']]\n",
    "    ratings_list = [train['rating'].values, test['rating'].values]\n",
    "\n",
    "    for j in range(2):\n",
    "        for n, i in enumerate(indices_list[j]):\n",
    "            idx = int(mid_to_tmd[i])\n",
    "            if idx in val_to_i.keys():\n",
    "                result_id[j].append(val_to_i[idx])\n",
    "                result_ratings[j].append(ratings_list[j][n])\n",
    "\n",
    "    train_indices, test_indices = np.array(result_id[0]) , np.array(result_id[1])\n",
    "    train_ratings, test_ratings = np.array(result_ratings[0]), np.array(result_ratings[1])\n",
    "    indices, scores = get_recommendation_for_user(train_indices,\n",
    "                                                train_ratings, \n",
    "                                                test_indices)\n",
    "    recommended_indices = test_indices[indices]\n",
    "    real_ratings = test_ratings[indices]\n",
    "    \n",
    "    return recommended_indices, real_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализацию NDCG возьмем отсюда:\n",
    "\n",
    "https://gist.github.com/bwhite/3726239\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def dcg_at_k(r, k, method=0):\n",
    "    \"\"\"Score is discounted cumulative gain (dcg)\n",
    "\n",
    "    Relevance is positive real values.  Can use binary\n",
    "    as the previous methods.\n",
    "\n",
    "    Example from\n",
    "    http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
    "    >>> r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
    "    >>> dcg_at_k(r, 1)\n",
    "    3.0\n",
    "    >>> dcg_at_k(r, 1, method=1)\n",
    "    3.0\n",
    "    >>> dcg_at_k(r, 2)\n",
    "    5.0\n",
    "    >>> dcg_at_k(r, 2, method=1)\n",
    "    4.2618595071429155\n",
    "    >>> dcg_at_k(r, 10)\n",
    "    9.6051177391888114\n",
    "    >>> dcg_at_k(r, 11)\n",
    "    9.6051177391888114\n",
    "\n",
    "    Args:\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "        k: Number of results to consider\n",
    "        method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "                If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "\n",
    "    Returns:\n",
    "        Discounted cumulative gain\n",
    "    \"\"\"\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        if method == 0:\n",
    "            return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "        elif method == 1:\n",
    "            return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "        else:\n",
    "            raise ValueError('method must be 0 or 1.')\n",
    "    return 0.\n",
    "\n",
    "\n",
    "def ndcg_at_k(r, k, method=0):\n",
    "    \"\"\"Score is normalized discounted cumulative gain (ndcg)\n",
    "\n",
    "    Relevance is positive real values.  Can use binary\n",
    "    as the previous methods.\n",
    "\n",
    "    Example from\n",
    "    http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
    "    >>> r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
    "    >>> ndcg_at_k(r, 1)\n",
    "    1.0\n",
    "    >>> r = [2, 1, 2, 0]\n",
    "    >>> ndcg_at_k(r, 4)\n",
    "    0.9203032077642922\n",
    "    >>> ndcg_at_k(r, 4, method=1)\n",
    "    0.96519546960144276\n",
    "    >>> ndcg_at_k([0], 1)\n",
    "    0.0\n",
    "    >>> ndcg_at_k([1], 2)\n",
    "    1.0\n",
    "\n",
    "    Args:\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "        k: Number of results to consider\n",
    "        method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "                If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "\n",
    "    Returns:\n",
    "        Normalized discounted cumulative gain\n",
    "    \"\"\"\n",
    "    dcg_max = dcg_at_k(sorted(r, reverse=True), k, method)\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k, method) / dcg_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.   5.   3.5  3.5  3.5  4.   4.   3.   3.5  4.   3.5  4.   4.   3.5  5.\n",
      "  3.5  3.5  4.   4.   3.   4.   3.5  4.   4.   4.   4.   3.5  4.   4.   3.5\n",
      "  3.5  4.   4.   3.   3.5  4.   3.5  4.   3.5]\n",
      "NDCG at 5 =  0.890388000511\n",
      "CPU times: user 2.23 s, sys: 45.9 ms, total: 2.27 s\n",
      "Wall time: 2.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "recommended_indices, real_ratings = process_recommendations(1)\n",
    "print(real_ratings)\n",
    "print('NDCG at 5 = ', ndcg_at_k(real_ratings, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.  5.  4.  5.  4.  5.  5.  5.  3.  2.  3.  3.  5.]\n",
      "NDCG at 5 =  0.88423165666\n",
      "CPU times: user 338 ms, sys: 11.3 ms, total: 350 ms\n",
      "Wall time: 354 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "recommended_indices, real_ratings = process_recommendations(2)\n",
    "print(real_ratings)\n",
    "print('NDCG at 5 = ', ndcg_at_k(real_ratings, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.  3.  5.  4.  4.  5.  4.  3.  5.  4.  5.  4.  4.  5.  3.  4.  5.  4.\n",
      "  5.  3.  5.  5.  3.  4.  3.  4.  5.  3.  2.  2.]\n",
      "NDCG at 5 =  0.779275067813\n",
      "CPU times: user 1.84 s, sys: 35.4 ms, total: 1.88 s\n",
      "Wall time: 1.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "recommended_indices, real_ratings = process_recommendations(3)\n",
    "print(real_ratings)\n",
    "print('NDCG at 5 = ', ndcg_at_k(real_ratings, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.  4.  4.  3.  4.  3.  4.  4.  2.  3.  3.  3.  2.  3.  3.  3.  3.  3.\n",
      "  4.  3.  2.  3.  3.]\n",
      "NDCG at 5 =  0.894710429175\n",
      "CPU times: user 727 ms, sys: 15.2 ms, total: 742 ms\n",
      "Wall time: 747 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "recommended_indices, real_ratings = process_recommendations(15)\n",
    "print(real_ratings)\n",
    "print('NDCG at 5 = ', ndcg_at_k(real_ratings, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из примеров видно, что сортировка рейтингов происходит не очень качественно, особенно если пользователь поставил всем фильмам одинаково высокие оценки (например 4.5 - 5). Но все же, сильно плохие оценки (1 - 2) не попадают в рекомендации (топ 5 фильмов)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
